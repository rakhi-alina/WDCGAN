{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary cross entropy loss\n",
    "\\begin{equation*}\n",
    "L(\\theta) = - \\frac{1}{n} \\sum_{i=1}^n [y_i log(p_i) + (1 - y_i) log(1 - p_i)]\n",
    "\\end{equation*}\n",
    "\n",
    "- Discriminator final probability is 1 => REAL IMAGE\n",
    "- Discriminator final probability is 0 => FAKE IMAGE\n",
    "\n",
    "Log values:\n",
    "- Log(1) => Loss would be 0\n",
    "- Log(0+) => Loss would be to - âˆž\n",
    "\n",
    "### Generator:\n",
    "\n",
    "Maximize D(G(z))\n",
    "\n",
    "\n",
    "### Discriminator:\n",
    "\n",
    "Maximize D(x) AND minimize D(G(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tricks to train GANs\n",
    "### https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import cv2\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "MAX : 255 and MIN: 0\n",
      "Normalized MAX : 1.0 and MIN: -1.0\n"
     ]
    }
   ],
   "source": [
    "def normalize(vector, a, b):\n",
    "    assert(a < b)\n",
    "    max_val = np.max(vector)\n",
    "    min_val = np.min(vector)\n",
    "\n",
    "    result = (b - a) * ( (vector - min_val) / (max_val - min_val) ) + a\n",
    "\n",
    "    return result\n",
    "\n",
    "(X_tmp, Y_train), _ = mnist.load_data()\n",
    "X_train = []\n",
    "for img in X_tmp:\n",
    "    #tmp = cv2.resize(img, (int(64),int(64)), interpolation = cv2.INTER_CUBIC)\n",
    "    #X_train.append(tmp)\n",
    "    X_train.append(img)\n",
    "    \n",
    "# Expand to have 1 channel (grey images)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print max and min and normalize\n",
    "print(\"MAX : \" + str(X_train.max()) + \" and MIN: \" + str(X_train.min()))\n",
    "X_train = normalize(X_train, -1, 1)\n",
    "print(\"Normalized MAX : \" + str(X_train.max()) + \" and MIN: \" + str(X_train.min()))\n",
    "\n",
    "assert(X_train.shape[1] == X_train.shape[2])\n",
    "base_path = \"/home/francesco/UQ/Job/Tumour_GAN/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters network and training\n",
    "epochs = 1000\n",
    "batchSize = 128\n",
    "lr = 0.0002\n",
    "Z_dim = 100\n",
    "mu, sigma = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show some samples\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(np.squeeze(X_train[i]), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise(batch_size, size, mu, sigma):\n",
    "    #return np.random.normal(mu, sigma, size=[batch_size, 1, 1, size])\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, size])\n",
    "\n",
    "\n",
    "def generator(z, trainable, reuse=False):\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        \n",
    "        fc1 = tf.layers.dense(z, 2*2*512)\n",
    "        \n",
    "        deconv_2 = tf.reshape(fc1, (-1, 2, 2, 512))\n",
    "        bn2 = tf.layers.batch_normalization(deconv_2, training=trainable)\n",
    "        lrelu2 = tf.nn.leaky_relu(bn2)\n",
    "        \n",
    "        deconv3 = tf.layers.conv2d_transpose(lrelu2, 256, 5, 2, padding='VALID')\n",
    "        bn3 = tf.layers.batch_normalization(deconv3, training=trainable)\n",
    "        lrelu3 = tf.nn.leaky_relu(bn3)\n",
    "        \n",
    "        deconv4 = tf.layers.conv2d_transpose(lrelu3, 128, 5, 2, padding='SAME')\n",
    "        bn4 = tf.layers.batch_normalization(deconv4, training=trainable)\n",
    "        lrelu4 = tf.nn.leaky_relu(bn4)\n",
    "        \n",
    "        deconv5 = tf.layers.conv2d_transpose(lrelu4, 1, 5, 2, padding='SAME')\n",
    "        output = tf.tanh(deconv5)\n",
    "        \n",
    "        print(z)\n",
    "        print(fc1)\n",
    "        print(lrelu2)\n",
    "        print(lrelu3)\n",
    "        print(lrelu4)\n",
    "        print(output)\n",
    "        \n",
    "    return output\n",
    "    \n",
    "\n",
    "def discriminator(x, trainable, reuse=False):\n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        conv1 = tf.layers.conv2d(x, 64, 5, 2, 'SAME')\n",
    "        lrelu1 = tf.nn.leaky_relu(conv1)\n",
    "\n",
    "        conv2 = tf.layers.conv2d(lrelu1, 128, 5, 2, 'SAME')\n",
    "        bn2 = tf.layers.batch_normalization(conv2, training=trainable)\n",
    "        lrelu2 = tf.nn.leaky_relu(bn2)\n",
    "\n",
    "        conv3 = tf.layers.conv2d(lrelu2, 256, 5, 1, 'SAME')\n",
    "        bn3 = tf.layers.batch_normalization(conv3, training=trainable)\n",
    "        lrelu3 = tf.nn.leaky_relu(bn3)\n",
    "\n",
    "        reshaped = tf.reshape(lrelu3, (-1, 4*4*256))\n",
    "        logits = tf.layers.dense(reshaped, 1)\n",
    "        probability = tf.sigmoid(logits)\n",
    "    \n",
    "    if not reuse:\n",
    "        print(x)\n",
    "        print(lrelu1)\n",
    "        print(lrelu2)\n",
    "        print(lrelu3)\n",
    "        print(reshaped)\n",
    "        print(probability)\n",
    "\n",
    "    return probability, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-e6569af30686>:10: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/francesco/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-5-e6569af30686>:13: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-e6569af30686>:16: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n",
      "Tensor(\"Z:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"generator/dense/BiasAdd:0\", shape=(?, 2048), dtype=float32)\n",
      "Tensor(\"generator/LeakyRelu:0\", shape=(?, 2, 2, 512), dtype=float32)\n",
      "Tensor(\"generator/LeakyRelu_1:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "Tensor(\"generator/LeakyRelu_2:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-e6569af30686>:40: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "Tensor(\"X:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"discriminator/LeakyRelu:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"discriminator/LeakyRelu_1:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"discriminator/LeakyRelu_2:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "Tensor(\"discriminator/Reshape:0\", shape=(?, 4096), dtype=float32)\n",
      "Tensor(\"discriminator/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim], name='Z')\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_train.shape[1], X_train.shape[2], X_train.shape[3]], name='X')\n",
    "isTrain = tf.placeholder(dtype=tf.bool)\n",
    "\n",
    "# Networks\n",
    "G_z = generator(Z, isTrain)\n",
    "_, D_logits_real = discriminator(X, isTrain)\n",
    "_, D_logits_fake = discriminator(G_z, isTrain, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminatorLoss(D_logits_real, D_logits_fake, label_smoothing=1):\n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_real,\n",
    "                                                labels=tf.ones_like(D_logits_real) * label_smoothing))\n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake,\n",
    "                                                labels=tf.zeros_like(D_logits_fake)))\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "    \n",
    "    return D_loss\n",
    "\n",
    "def generatorLoss(D_logits_fake):\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake,\n",
    "                                                labels=tf.ones_like(D_logits_fake)))\n",
    "    return G_loss\n",
    "\n",
    "D_loss = discriminatorLoss(D_logits_real, D_logits_fake, 0.9)\n",
    "G_loss = generatorLoss(D_logits_fake)\n",
    "\n",
    "# Losses have minus sign because I have to maximize them\n",
    "#D_loss = - tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_fake))\n",
    "#G_loss = - tf.reduce_mean(tf.log(D_fake))\n",
    "\n",
    "all_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in all_vars if var.name.startswith('discriminator')]\n",
    "G_vars = [var for var in all_vars if var.name.startswith('generator')]\n",
    "\n",
    "# Optimize\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops): \n",
    "    D_optimizer = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(D_loss, var_list=D_vars)\n",
    "    G_optimizer = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(G_loss, var_list=G_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the generator and discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 100)\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('D_loss', D_loss)\n",
    "tf.summary.scalar('G_loss', G_loss)\n",
    "\n",
    "# MERGE SUMMARIES - Merge all summaries into a single op\n",
    "merged_summ = tf.summary.merge_all()\n",
    "\n",
    "# VISUALIZE => tensorboard --logdir=.\n",
    "summaries_dir = base_path + \"checkpoints\"\n",
    "\n",
    "# Test noise\n",
    "testNoise = sample_noise(6, Z_dim, mu, sigma)\n",
    "print(testNoise.shape)\n",
    "\n",
    "def saveImages(images, epoch):    \n",
    "    for i in range(len(images)):\n",
    "        mpimg.imsave(base_path + \"images/out-\" + str(epoch) + \"-\" + str(i) + \".png\", np.squeeze(G_output[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9468dd3c9703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             _, summary = sess.run([G_optimizer, merged_summ], feed_dict={ X: X_train[j:j+batchSize],\n\u001b[1;32m     25\u001b[0m                                                                           \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                                                           isTrain: True })\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mglobalStep\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobalStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "indices = list(range(len(X_train)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(summaries_dir, graph=tf.get_default_graph())\n",
    "    \n",
    "    globalStep = 0\n",
    "    for i in range(epochs):        \n",
    "        # Shuffle dataset every epoch\n",
    "        print(\"Epoch \" + str(i))\n",
    "        np.random.shuffle(indices)\n",
    "        X_train = X_train[indices]\n",
    "        \n",
    "        for j in range(0, len(X_train), batchSize):\n",
    "            noise = sample_noise(len(X_train[j:j+batchSize]), Z_dim, mu, sigma)\n",
    "\n",
    "            _ = sess.run(D_optimizer, feed_dict={ X: X_train[j:j+batchSize], \n",
    "                                                  Z: noise,\n",
    "                                                  isTrain: True})\n",
    "\n",
    "            noise = sample_noise(len(X_train[j:j+batchSize]), Z_dim, mu, sigma)\n",
    "            _, summary = sess.run([G_optimizer, merged_summ], feed_dict={ X: X_train[j:j+batchSize],\n",
    "                                                                          Z: noise,\n",
    "                                                                          isTrain: True })\n",
    "            globalStep+=1\n",
    "            summary_writer.add_summary(summary, globalStep)\n",
    "\n",
    "        # Check results every epoch\n",
    "        save_path = saver.save(sess, base_path + \"checkpoints/model.ckpt\")\n",
    "        G_output = sess.run(G_z, feed_dict={ Z: testNoise,\n",
    "                                            isTrain: False })\n",
    "        saveImages(G_output, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
