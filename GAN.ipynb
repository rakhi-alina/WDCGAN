{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary cross entropy loss\n",
    "\\begin{equation*}\n",
    "L(\\theta) = - \\frac{1}{n} \\sum_{i=1}^n [y_i log(p_i) + (1 - y_i) log(1 - p_i)]\n",
    "\\end{equation*}\n",
    "\n",
    "- Discriminator final probability is 1 => REAL IMAGE\n",
    "- Discriminator final probability is 0 => FAKE IMAGE\n",
    "\n",
    "Log values:\n",
    "- Log(1) => Loss would be 0\n",
    "- Log(0+) => Loss would be to - âˆž\n",
    "\n",
    "### Generator:\n",
    "\n",
    "Maximize D(G(z))\n",
    "\n",
    "\n",
    "### Discriminator:\n",
    "\n",
    "Maximize D(x) AND minimize D(G(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tricks to train GANs\n",
    "### https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "MAX : 255 and MIN: 0\n",
      "Normalized MAX : 1.0 and MIN: -1.0\n"
     ]
    }
   ],
   "source": [
    "def normalize(vector, a, b):\n",
    "    assert(a < b)\n",
    "    max_val = np.max(vector)\n",
    "    min_val = np.min(vector)\n",
    "\n",
    "    result = (b - a) * ( (vector - min_val) / (max_val - min_val) ) + a\n",
    "\n",
    "    return result\n",
    "\n",
    "(X_train, Y_train), _ = mnist.load_data()\n",
    "\n",
    "# Expand to have 1 channel (grey images)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print max and min and normalize\n",
    "print(\"MAX : \" + str(X_train.max()) + \" and MIN: \" + str(X_train.min()))\n",
    "X_train = normalize(X_train, -1, 1)\n",
    "print(\"Normalized MAX : \" + str(X_train.max()) + \" and MIN: \" + str(X_train.min()))\n",
    "\n",
    "assert(X_train.shape[1] == X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters network and training\n",
    "epochs = 1000\n",
    "batchSize = 32\n",
    "lr = 0.0002\n",
    "Z_dim = 100\n",
    "mu, sigma = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show some samples\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(np.squeeze(X_train[i]), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upConv2DLayer(inputTensor, numFilters, size=5, stride=2, name=None, bn=True, activation=True):\n",
    "    #initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    #tf.truncated_normal_initializer(stddev=0.1)\n",
    "    \n",
    "    output = tf.keras.layers.Conv2DTranspose(numFilters, # Number of output channels\n",
    "                                            kernel_size=(size,size), # Size of each filter\n",
    "                                            strides=(stride,stride), \n",
    "                                            padding=\"same\", \n",
    "                                            activation=None,\n",
    "                                            use_bias=False,\n",
    "                                            name=name)(inputTensor)\n",
    "    print(output)\n",
    "    if bn:\n",
    "        output = tf.keras.layers.BatchNormalization()(output)\n",
    "        print(output)\n",
    "        \n",
    "    if activation:\n",
    "        output = tf.keras.layers.LeakyReLU()(output)\n",
    "        print(output)\n",
    "         \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Generator network\\ndef generator(z, reuse=False):\\n    \\n    with tf.variable_scope(\"generator\", reuse=reuse):\\n        print(z)\\n        fc1 = tf.keras.layers.Dense(7*7*256, use_bias=False)(z)\\n        print(fc1)\\n        bn1 = tf.keras.layers.BatchNormalization()(fc1)\\n        print(bn1)\\n        relu1 = tf.keras.layers.LeakyReLU()(bn1)\\n        print(relu1)\\n        \\n        reshaped = tf.reshape(relu1, shape=[-1, 7, 7, 256])\\n        print(reshaped)\\n\\n        upConv1 = upConv2DLayer(reshaped, 128, 5, 1, \"upConv1\")\\n        upConv2 = upConv2DLayer(upConv1, 64, 5, 2, \"upConv2\")\\n        upConv3 = upConv2DLayer(upConv2, 1, 5, 2, \"upConv3\", bn=False, activation=False)\\n        \\n        output = tf.nn.tanh(upConv3)\\n        print(output)\\n        \\n        return output\\n    \\n# Discriminator\\ndef discriminator(x, reuse=False, dropout=0.3):\\n    \\n    with tf.variable_scope(\"discriminator\", reuse=reuse):\\n        conv1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\\'same\\')(x)\\n        relu1 = tf.keras.layers.LeakyReLU()(conv1)\\n        drop1 = tf.keras.layers.Dropout(dropout)(relu1)\\n        \\n        conv2 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\\'same\\')(drop1)\\n        relu2 = tf.keras.layers.LeakyReLU()(conv2)\\n        drop2 = tf.keras.layers.Dropout(dropout)(relu2)\\n\\n        flattened = tf.keras.layers.Flatten()(drop2)\\n        output = tf.keras.layers.Dense(1)(flattened)\\n        output = tf.nn.sigmoid(output)\\n    if not reuse:\\n        print(x)\\n        print(conv1)\\n        print(relu1)\\n        print(drop1)\\n        print(conv2)\\n        print(relu2)\\n        print(drop2)\\n        print(flattened)\\n        print(output)\\n        \\n    return output'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample noise for generator\n",
    "def sample_Z(batch_size, img_size, mu, sigma):\n",
    "    return np.random.normal(mu, sigma, size=[batch_size, img_size])\n",
    "    #return np.random.uniform(-1., 1., size=[batch_size, img_size])\n",
    "\n",
    "    \n",
    "'''# Generator network\n",
    "def generator(z, reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        print(z)\n",
    "        fc1 = tf.keras.layers.Dense(7*7*256, use_bias=False)(z)\n",
    "        print(fc1)\n",
    "        bn1 = tf.keras.layers.BatchNormalization()(fc1)\n",
    "        print(bn1)\n",
    "        relu1 = tf.keras.layers.LeakyReLU()(bn1)\n",
    "        print(relu1)\n",
    "        \n",
    "        reshaped = tf.reshape(relu1, shape=[-1, 7, 7, 256])\n",
    "        print(reshaped)\n",
    "\n",
    "        upConv1 = upConv2DLayer(reshaped, 128, 5, 1, \"upConv1\")\n",
    "        upConv2 = upConv2DLayer(upConv1, 64, 5, 2, \"upConv2\")\n",
    "        upConv3 = upConv2DLayer(upConv2, 1, 5, 2, \"upConv3\", bn=False, activation=False)\n",
    "        \n",
    "        output = tf.nn.tanh(upConv3)\n",
    "        print(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Discriminator\n",
    "def discriminator(x, reuse=False, dropout=0.3):\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        conv1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "        relu1 = tf.keras.layers.LeakyReLU()(conv1)\n",
    "        drop1 = tf.keras.layers.Dropout(dropout)(relu1)\n",
    "        \n",
    "        conv2 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(drop1)\n",
    "        relu2 = tf.keras.layers.LeakyReLU()(conv2)\n",
    "        drop2 = tf.keras.layers.Dropout(dropout)(relu2)\n",
    "\n",
    "        flattened = tf.keras.layers.Flatten()(drop2)\n",
    "        output = tf.keras.layers.Dense(1)(flattened)\n",
    "        output = tf.nn.sigmoid(output)\n",
    "    if not reuse:\n",
    "        print(x)\n",
    "        print(conv1)\n",
    "        print(relu1)\n",
    "        print(drop1)\n",
    "        print(conv2)\n",
    "        print(relu2)\n",
    "        print(drop2)\n",
    "        print(flattened)\n",
    "        print(output)\n",
    "        \n",
    "    return output'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):        \n",
    "        fc1 = tf.layers.dense(inputs=z, units=256, activation=tf.nn.leaky_relu)\n",
    "        fc2 = tf.layers.dense(inputs=fc1, units=784, activation=None)\n",
    "        logits = tf.nn.tanh(fc2)\n",
    "        output = tf.reshape(logits, shape=[-1, 28, 28, 1])\n",
    "        \n",
    "        print(\"Generator:\")\n",
    "        print(z)\n",
    "        print(fc1)\n",
    "        print(fc2)\n",
    "        print(logits)\n",
    "        print(output)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def discriminator(x, reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        x = tf.layers.Flatten()(x)\n",
    "        fc1 = tf.layers.dense(inputs=x, units=256, activation=tf.nn.leaky_relu)\n",
    "        fc2 = tf.layers.dense(inputs=fc1, units=1, activation=None)\n",
    "        prob = tf.nn.sigmoid(fc2)\n",
    "        \n",
    "        if not reuse:\n",
    "            print(\"\\nDiscriminator:\")\n",
    "            print(x)\n",
    "            print(fc1)\n",
    "            print(fc2)\n",
    "            print(prob)\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-3b2f5cbc7f58>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/francesco/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Generator:\n",
      "Tensor(\"Z:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"generator/dense/LeakyRelu:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"generator/dense_1/BiasAdd:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"generator/Tanh:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"generator/Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "Discriminator:\n",
      "Tensor(\"discriminator/flatten/Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"discriminator/dense/LeakyRelu:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"discriminator/dense_1/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"discriminator/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
      "[<tf.Variable 'generator/dense/kernel:0' shape=(100, 256) dtype=float32_ref>, <tf.Variable 'generator/dense/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'generator/dense_1/kernel:0' shape=(256, 784) dtype=float32_ref>, <tf.Variable 'generator/dense_1/bias:0' shape=(784,) dtype=float32_ref>]\n",
      "[<tf.Variable 'discriminator/dense/kernel:0' shape=(784, 256) dtype=float32_ref>, <tf.Variable 'discriminator/dense/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/dense_1/kernel:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'discriminator/dense_1/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Generator noise input\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim], name='Z')\n",
    "\n",
    "# Discriminator input\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_train.shape[1], X_train.shape[2], X_train.shape[3]], name='X')\n",
    "\n",
    "# Networks\n",
    "G_z = generator(Z)\n",
    "\n",
    "D_fake = discriminator(G_z, reuse=False)\n",
    "D_real = discriminator(X, reuse=True)\n",
    "\n",
    "# Loss\n",
    "D_loss = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_fake))\n",
    "G_loss = tf.reduce_mean(tf.log(D_fake))\n",
    "\n",
    "# Optimizer\n",
    "D_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\n",
    "G_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\n",
    "print(G_var_list)\n",
    "print(D_var_list)\n",
    "\n",
    "D_optimizer = tf.train.AdamOptimizer(lr, beta1 = 0.5).minimize(-D_loss, var_list=D_var_list)\n",
    "G_optimizer = tf.train.AdamOptimizer(lr, beta1 = 0.5).minimize(-G_loss, var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def discriminatorLoss(dis_real, dis_fake, smoothing=1.0):\\n\\n    dis_real_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_real, labels=tf.ones_like(dis_real) * smoothing)\\n    dis_fake_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.zeros_like(dis_fake))\\n    \\n    dis_loss_real = tf.reduce_mean(dis_real_ce)\\n    dis_loss_fake = tf.reduce_mean(dis_fake_ce)\\n    \\n    return tf.reduce_mean(dis_real_ce + dis_fake_ce)\\n\\n\\ndef generatorLoss(dis_fake):\\n    gen_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.ones_like(dis_fake))\\n\\n    return tf.reduce_mean(gen_ce)\\n    \\nD_loss = discriminatorLoss(D_real, D_fake)\\nG_loss = generatorLoss(D_fake)\\n\\nD_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\\nD_optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(D_loss, var_list=D_var)\\n\\nG_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\\nG_optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss, var_list=G_var)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def discriminatorLoss(dis_real, dis_fake, smoothing=1.0):\n",
    "\n",
    "    dis_real_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_real, labels=tf.ones_like(dis_real) * smoothing)\n",
    "    dis_fake_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.zeros_like(dis_fake))\n",
    "    \n",
    "    dis_loss_real = tf.reduce_mean(dis_real_ce)\n",
    "    dis_loss_fake = tf.reduce_mean(dis_fake_ce)\n",
    "    \n",
    "    return tf.reduce_mean(dis_real_ce + dis_fake_ce)\n",
    "\n",
    "\n",
    "def generatorLoss(dis_fake):\n",
    "    gen_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.ones_like(dis_fake))\n",
    "\n",
    "    return tf.reduce_mean(gen_ce)\n",
    "    \n",
    "D_loss = discriminatorLoss(D_real, D_fake)\n",
    "G_loss = generatorLoss(D_fake)\n",
    "\n",
    "D_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\n",
    "D_optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(D_loss, var_list=D_var)\n",
    "\n",
    "G_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss, var_list=G_var)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImages(images, globalStep, samples=9):    \n",
    "    size = np.sqrt(samples)\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    for i in range(np.minimum(samples, len(images))):\n",
    "        plt.subplot(size, size, i+1)\n",
    "        plt.imshow(np.squeeze(images[i]), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('./images/image_' + str(globalStep) + '.png')\n",
    "    #plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the generator and discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('D_loss', D_loss)\n",
    "tf.summary.scalar('G_loss', G_loss)\n",
    "\n",
    "# MERGE SUMMARIES - Merge all summaries into a single op\n",
    "merged_summ = tf.summary.merge_all()\n",
    "\n",
    "# VISUALIZE => tensorboard --logdir=.\n",
    "summaries_dir = \"./checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(X_train)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(summaries_dir, graph=tf.get_default_graph())\n",
    "    \n",
    "    # Epochs\n",
    "    globalStep = 1\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # Shuffle dataset every epoch\n",
    "        print(\"Epoch \" + str(i))\n",
    "        np.random.shuffle(indices)\n",
    "        X_train = X_train[indices]\n",
    "        \n",
    "        for j in range(0, len(X_train), batchSize):\n",
    "            \n",
    "            # Sample noise\n",
    "            noise = sample_Z(len(X_train[j:j+batchSize]), Z_dim, mu, sigma)\n",
    "            \n",
    "            _ = sess.run(D_optimizer, feed_dict={ X: X_train[j:j+batchSize], \n",
    "                                                  Z: noise })\n",
    "\n",
    "            _, summary = sess.run([G_optimizer, merged_summ], feed_dict={ X: X_train[j:j+batchSize],\n",
    "                                                                          Z: noise })\n",
    "            summary_writer.add_summary(summary, globalStep)\n",
    "            \n",
    "            globalStep += 1\n",
    "        \n",
    "        # Check results every epoch\n",
    "        save_path = saver.save(sess, \"./checkpoints/model.ckpt\")                \n",
    "        output = sess.run(G_z, feed_dict={ Z: noise })\n",
    "        saveImages(output, globalStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
